server:
  http_listen_port: 3200 # Port for Tempo's API and UI (accessed by Grafana)

distributor:
  receivers: # Define protocols Tempo can receive traces on
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317 # Default OTLP gRPC port
        http:
          endpoint: 0.0.0.0:4318 # Default OTLP HTTP port

ingester:
  trace_idle_period: 10s               # time before flushing an idle trace
  max_block_bytes: 1048576             # 1MB cut traces that are too big
  max_block_duration: 5m               # cut traces that are too long

compactor:
  compaction:
    compaction_window: 1h              # blocks in this time window will be compacted together
    max_compaction_objects: 1000000    # maximum number of objects per compacted block
    block_retention: 72h               # Overall Tempo trace retention
    compacted_block_retention: 10m     # How long to keep compacted blocks locally

storage:
  trace:
    backend: local                     # Use local filesystem for storage
    local:
      path: /data/blocks               # Path within the volume

# Optional: Overrides default configuration for query service
# querier:
#   max_concurrent_queries: 10
#   query_timeout: 1m

metrics_generator: # Optional: Generate metrics from traces (e.g., RED metrics)
  storage:
    path: /data/generator/wal
    remote_write:
      - url: http://prometheus:9090/api/v1/write # Send generated metrics to Prometheus
        send_exemplars: true

overrides:
  # Example: Set longer retention for specific tenants if using multi-tenancy
  # per_tenant_override_config: /etc/tempo/overrides.yaml
  defaults:
    metrics_generator:
      processors: [service-graphs, span-metrics] # Enable metrics generation